{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结果可视化分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# 设定log文件的路径\n",
    "log_dir = '/Users/yekai/github/saved_out/logs/finalexp/PAN_VGGFace2_r3p9p10_eval0_idx50_lambdaS_1e-4_omiga0599_total120_20250401'\n",
    "# head = \"exp_data_\"\n",
    "head = \"output_\"\n",
    "dir_name = os.path.basename(log_dir)\n",
    "# 定义需要提取的指标名称\n",
    "metrics = [\n",
    "    'BRISQUE_mean', 'BRISQUE_std', 'CLIPIQA_mean', 'CLIPIQA_std', \n",
    "    'CLIP_Face_IQA_mean', 'CLIP_Face_IQA_std', 'CLIP_IQAC_mean', 'CLIP_IQAC_std',\n",
    "    'IMS_CLIP_ViT-B/32_mean', 'IMS_CLIP_ViT-B/32_std', 'IMS_VGG-Face_cosine_mean',\n",
    "    'IMS_VGG-Face_cosine_std', 'LIQE_Quality_mean', 'LIQE_Quality_std',\n",
    "    'LIQE_Scene_Human_mean', 'LIQE_Scene_Human_std', 'SDS_mean', 'SDS_std', \n",
    "    'dreambooth train loss', 'loss', 'lr', \n",
    "\n",
    "    'max_noise_r',\n",
    "    'noise_L0',\n",
    "    'ciede2000_score',\n",
    "    'pix_change_mean',\n",
    "    'change_area_mean',\n",
    "\n",
    "    'experiment_time_minutes',\n",
    "]\n",
    "\n",
    "# 定义正则表达式提取参数和时间戳\n",
    "param_pattern = re.compile(rf'{head}(.*?)-(\\d+)\\.log')\n",
    "\n",
    "# 定义存储结果的字典\n",
    "data = {}\n",
    "\n",
    "# 正则表达式用于提取最后一步的时间，确保进度条两个数字相同，且 [hh:mm:ss] 时间前后没有空格\n",
    "# time_pattern = re.compile(r'meta poison with model ensemble:.*?(\\d+)/\\1.*?(\\d+:\\d+:\\d+)')\n",
    "time_pattern = r\"meta poison with model ensemble: 100%\\|[^\\|]+\\| (\\d+)/\\1 \\[(\\d{1,2}:\\d{2}(?::\\d{2})?)\"\n",
    "\n",
    "for filename in os.listdir(log_dir):\n",
    "    if filename.endswith('.log'):\n",
    "        match = param_pattern.match(filename)\n",
    "        if match:\n",
    "            param_str = match.group(1)  # 参数部分\n",
    "            timestamp = match.group(2)  # 时间戳\n",
    "\n",
    "            # 读取log文件内容\n",
    "            with open(os.path.join(log_dir, filename), 'r') as f:\n",
    "                content = f.read()\n",
    "            total_time_minutes = None\n",
    "            # 提取实验耗时（找到最后一个匹配的时间，确保进度条两个数字相同，并且时间前后没有空格）\n",
    "            time_match = re.findall(time_pattern, content)\n",
    "            if time_match:\n",
    "                last_time = time_match[1][1] # 提取最后一个step的时间\n",
    "                # print(last_time)\n",
    "                time_map = last_time.split(':')\n",
    "                if len(time_map) == 3:\n",
    "                    h, m, s = map(int, last_time.split(':'))\n",
    "                    total_time_minutes = h * 60 + m + s / 60  # 转换为分钟\n",
    "                if len(time_map) == 2:\n",
    "                    m, s = map(int, last_time.split(':'))  # 转换为分钟、秒\n",
    "                    total_time_minutes = m + s / 60  # 转换为分钟\n",
    "                # print(total_time_minutes)\n",
    "            else:\n",
    "                print('No time found in log file:', filename)\n",
    "                total_time_minutes = 0\n",
    "\n",
    "            # 提取各个指标\n",
    "            result = {}\n",
    "            for metric in metrics[:-1]:  # 最后一个是时间指标，需要单独处理\n",
    "                # 正则匹配获取指标值\n",
    "                match = re.search(fr'{metric}\\s+([-\\d.]+)', content)\n",
    "                if match:\n",
    "                    try:\n",
    "                        result[metric.replace('/', '_')] = float(match.group(1))\n",
    "                    except ValueError:\n",
    "                        break\n",
    "            \n",
    "            # 存储实验耗时\n",
    "            result['experiment_time_minutes'] = total_time_minutes\n",
    "            \n",
    "\n",
    "            # 如果参数组合还未在字典中，初始化列表\n",
    "            if param_str not in data:\n",
    "                data[param_str] = []\n",
    "            # max_noise_r 向上方取整\n",
    "            if 'max_noise_r' in result:\n",
    "                result['max_noise_r'] = math.ceil(result['max_noise_r'])\n",
    "            # 存储结果\n",
    "            data[param_str].append(result)\n",
    "\n",
    "# 计算平均值并可视化的步骤与之前相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_df_by_numeric_values(df):\n",
    "    # 将索引转换为 Series 来提取数值部分\n",
    "    index_series = df.index.to_series()\n",
    "    \n",
    "    # 提取第一列中的所有数值，并将它们转换为数值列表\n",
    "    numeric_values = index_series.str.findall(r'\\d+\\.?\\d*').apply(lambda x: list(map(float, x)))\n",
    "    \n",
    "    # 将提取的数值列表作为新的列添加到 DataFrame 中\n",
    "    df['numeric_values'] = numeric_values\n",
    "    \n",
    "    # 按照提取出的数值列表进行排序\n",
    "    sorted_df = df.sort_values(by='numeric_values', ascending=True)\n",
    "    \n",
    "    # 删除临时列 'numeric_values'\n",
    "    sorted_df = sorted_df.drop(columns=['numeric_values'])\n",
    "    \n",
    "    # 返回排序后的 DataFrame\n",
    "    return sorted_df\n",
    "\n",
    "\n",
    "avg_data = {}\n",
    "for param_str, experiments in data.items():\n",
    "    # 将同组实验结果转为DataFrame\n",
    "    df = pd.DataFrame(experiments)\n",
    "    \n",
    "    # 去掉每列的最高值和最低值后计算平均值\n",
    "    def trimmed_mean(series):\n",
    "        sorted_series = series.sort_values()\n",
    "        # 去掉一个最高和一个最低值\n",
    "        if len(sorted_series) > 2:\n",
    "            trimmed_series = sorted_series[1:-1]\n",
    "            return trimmed_series.mean()\n",
    "        else:\n",
    "            return series.mean()\n",
    "    \n",
    "    avg_data[param_str] = df.apply(trimmed_mean).to_dict()\n",
    "\n",
    "# 将平均结果转换为DataFrame便于分析\n",
    "avg_df = pd.DataFrame.from_dict(avg_data, orient='index')\n",
    "avg_df_sorted = sort_df_by_numeric_values(avg_df)\n",
    "test_kind_num = len(data)\n",
    "\n",
    "show_metrics = ['IMS_VGG-Face_cosine_mean',\n",
    "                'ciede2000_score', #\n",
    "                'SDS_mean', \n",
    "                'CLIP_IQAC_mean',\n",
    "                # 'max_noise_r',#\n",
    "                'LIQE_Quality_mean',\n",
    "                # 'pix_change_mean',#\n",
    "                'IMS_CLIP_ViT-B_32_mean',\n",
    "                'BRISQUE_mean',\n",
    "\n",
    "                ]\n",
    "# 针对每个指标分别绘制图表\n",
    "save_path = os.path.join(\"/Users/yekai/github/saved_out/result_save\",dir_name)\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "# for metric in show_metrics:\n",
    "#     pic_path = os.path.join(save_path, metric + '.png')\n",
    "#     if os.path.exists(pic_path):\n",
    "#         print(f\"{metric} already exists, showing it\")\n",
    "#         # matplotlib  show saved png file\n",
    "#         img = mpimg.imread(pic_path)\n",
    "#         imgplot = plt.imshow(img)\n",
    "#         plt.axis('off')\n",
    "#         plt.show()\n",
    "#     else:\n",
    "#         plt.figure(figsize=(15, test_kind_num*1),dpi=100)\n",
    "#         avg_df_sorted[metric].plot(kind='barh')  # 更改为横向柱状图\n",
    "#         plt.title(f'{metric}')\n",
    "#         plt.ylabel('Parameter Settings')\n",
    "#         plt.xlabel(f'Average {metric}')\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig(pic_path)\n",
    "#         plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调整最大显示行数和列数\n",
    "pd.set_option('display.max_rows', None)  # 显示所有行\n",
    "pd.set_option('display.max_columns', None)  # 显示所有列\n",
    "pd.set_option('display.width', 1000)  # 调整宽度，避免列换行\n",
    "show_df = avg_df_sorted[show_metrics]\n",
    "show_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "show_df.to_csv(os.path.join(save_path, 'data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analyse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
