{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/yekai/conda_envs/Metacloakp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-06-30 21:38:13.450784: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-30 21:38:13.500309: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-30 21:38:14.163227: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAPB_path: /data/home/yekai/github/DiffAdvPerturbationBench\n",
      "now_dir_path: /data/home/yekai/github/DiffAdvPerturbationBench/multi-dreambooth\n",
      "model_path: /data/home/yekai/github/DiffAdvPerturbationBench/multi-dreambooth/train_outputs/MultiATK_SD21_VGGFace2_r8_idx10_1idmatk/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/yekai/conda_envs/Metacloakp/lib/python3.10/site-packages/diffusers/models/modeling_utils.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
      "/data/home/yekai/conda_envs/Metacloakp/lib/python3.10/site-packages/transformers/modeling_utils.py:415: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x77e9bc102a30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import torch\n",
    "from torch import autocast\n",
    "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "now_dir_path = os.getcwd()\n",
    "DAPB_path = os.path.dirname(now_dir_path)\n",
    "print(f\"DAPB_path: {DAPB_path}\")\n",
    "print(f\"now_dir_path: {now_dir_path}\")\n",
    "trained_model_path = os.path.join(now_dir_path, \"train_outputs\")\n",
    "gen_outputs_path = os.path.join(now_dir_path, \"gen_outputs\")\n",
    "\n",
    "# If you want to use previously trained model saved in gdrive, replace this with the full path of model in gdrive\n",
    "taskname = \"MultiATK_SD21_VGGFace2_r8_idx10_1idmatk\"\n",
    "spwords_file = \"spwords.json\"\n",
    "totalsteps = 10000\n",
    "save_path = os.path.join(gen_outputs_path, taskname)\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "model_path = os.path.join(trained_model_path, taskname, str(totalsteps))\n",
    "print(f\"model_path: {model_path}\")\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_path, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
    "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "pipe.enable_xformers_memory_efficient_attention()\n",
    "g_cuda = None\n",
    "#@markdown Can set random seed here for reproducibility.\n",
    "g_cuda = torch.Generator(device='cuda')\n",
    "seed = 52362 #@param {type:\"number\"}\n",
    "g_cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:31<00:00,  3.18it/s]\n",
      "100%|██████████| 100/100 [00:31<00:00,  3.18it/s]\n",
      "100%|██████████| 100/100 [00:31<00:00,  3.18it/s]\n",
      "100%|██████████| 100/100 [00:31<00:00,  3.18it/s]\n",
      "100%|██████████| 100/100 [00:31<00:00,  3.18it/s]\n",
      "100%|██████████| 100/100 [00:31<00:00,  3.18it/s]\n",
      "100%|██████████| 100/100 [00:31<00:00,  3.18it/s]\n",
      "100%|██████████| 100/100 [00:31<00:00,  3.18it/s]\n",
      "100%|██████████| 100/100 [00:31<00:00,  3.18it/s]\n",
      "100%|██████████| 100/100 [00:31<00:00,  3.18it/s]\n"
     ]
    }
   ],
   "source": [
    "special_text = []\n",
    "with open(f\"{now_dir_path}/{spwords_file}\", \"r\") as f:\n",
    "    special_text = json.load(f)[\"spwords_list\"]\n",
    "# special_text = [\n",
    "#     \"vux\", \"jiq\", \"qem\", \"zod\", \"dul\", \"wex\", \"hob\", \"taf\", \"yib\", \"nuz\",\n",
    "#     \"gax\", \"fep\", \"cim\", \"pyk\", \"teb\", \"lom\", \"sir\", \"dap\", \"kex\", \"yoc\",\n",
    "#     \"mib\", \"zow\", \"ruk\", \"hif\", \"cun\", \"baj\", \"tox\", \"geq\", \"vyx\", \"qum\",\n",
    "#     \"rek\", \"sov\", \"hax\", \"zud\", \"dif\", \"koy\", \"wen\", \"jib\", \"rax\", \"miv\",\n",
    "#     \"pob\", \"lut\", \"seg\", \"yox\", \"cud\", \"vig\", \"bez\", \"nam\", \"foj\", \"xur\"\n",
    "# ]\n",
    "# special_text = [\n",
    "#      \"vux\", \"jiq\", \"qem\", \"zod\", \"dul\", \"wex\", \"hob\", \"taf\", \"yib\", \"nuz\",\n",
    "# ]\n",
    "# save_path = f\"/data/home/yekai/github/sampleall/multi-dreambooth/gen_output/{taskname}\"\n",
    "# if not os.path.exists(save_path):\n",
    "#     os.mkdir(save_path)\n",
    "# instance_num = len(special_text)\n",
    "instance_num = 10\n",
    "prompt_list = [f\"a photo of {special_text[i]} person\" for i in range(instance_num)]\n",
    "# prompt_list = [f\"a noised photo of {special_text[i]} person\" for i in range(instance_num)] #@param {type:\"string\"}\n",
    "# prompt_list = [f\"a noised photo of person\" for i in range(instance_num)]\n",
    "negative_prompt = \"\" #@param {type:\"string\"}\n",
    "num_samples = 16 #@param {type:\"number\"}\n",
    "guidance_scale = 7.5 #@param {type:\"number\"}\n",
    "num_inference_steps = 100 #@param {type:\"number\"}\n",
    "height = 512 #@param {type:\"number\"}\n",
    "width = 512 #@param {type:\"number\"}\n",
    "for i in range(instance_num):\n",
    "    with autocast(\"cuda\"), torch.inference_mode():\n",
    "        images = pipe(\n",
    "            prompt_list[i],\n",
    "            height=height,\n",
    "            width=width,\n",
    "            negative_prompt=negative_prompt,\n",
    "            num_images_per_prompt=num_samples,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=guidance_scale,\n",
    "            generator=g_cuda\n",
    "        ).images\n",
    "    if not os.path.exists(f\"{save_path}/{i}\"):\n",
    "        os.mkdir(f\"{save_path}/{i}\")\n",
    "    for index, img in enumerate(images):\n",
    "        img.save(f\"{save_path}/{i}/{index}.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 评估生成图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "sys.path.append(\"/data/home/yekai/github/MetaCloak\")\n",
    "sys.path.append(\"/data/home/yekai/github/MetaCloak/robust_facecloak\")\n",
    "\n",
    "\n",
    "from eval_score import get_score\n",
    "import numpy as np\n",
    "from robust_facecloak.attacks.worker.differential_color_functions import rgb2lab_diff, ciede2000_diff\n",
    "from robust_facecloak.generic.data_utils import PromptDataset, load_data_by_picname\n",
    "\n",
    "def find_max_pixel_change(original_img, noisy_img):\n",
    "    diff = torch.abs(original_img - noisy_img)\n",
    "    \n",
    "    # Find the maximum pixel difference\n",
    "    max_change = torch.max(diff)\n",
    "    \n",
    "    return max_change.item()\n",
    "\n",
    "def get_L0(original_img, noisy_img):\n",
    "    diff = torch.abs(original_img - noisy_img)\n",
    "    diff_L0 = torch.sum(diff > 0, dim=(1, 2, 3))\n",
    "    # Find the maximum pixel difference\n",
    "    mean_L0 = torch.mean(diff_L0.float())\n",
    "    return mean_L0.item()\n",
    "\n",
    "def get_L1(original_img, noisy_img):\n",
    "    diff = torch.abs(original_img - noisy_img)\n",
    "    diff_L1 = torch.sum(diff, dim=(1, 2, 3))\n",
    "    mean_L1 = torch.mean(diff_L1.float())\n",
    "    return mean_L1.item()\n",
    "\n",
    "def get_change_p(original_img, noisy_img):\n",
    "    diff = torch.abs(original_img - noisy_img)\n",
    "    diff_L0_all = torch.sum(diff > 0, dim=(0, 1, 2, 3))\n",
    "    pix_num_all = original_img.shape[0] * original_img.shape[1] * original_img.shape[2] * original_img.shape[3]\n",
    "    change_p = diff_L0_all / pix_num_all\n",
    "    return change_p.item()\n",
    "\n",
    "def get_ciede2000_diff(ori_imgs,advimgs):\n",
    "    device = torch.device('cuda')\n",
    "    ori_imgs_0_1 = ori_imgs/255\n",
    "    advimgs_0_1 = advimgs/255\n",
    "    advimgs_0_1.clamp_(0,1)\n",
    "    # print(f'ori_imgs_0_1.min:{ori_imgs_0_1.min()}, ori_imgs_0_1.max:{ori_imgs_0_1.max()}')\n",
    "    # print(f'advimgs_0_1.min:{advimgs_0_1.min()}, advimgs_0_1.max:{advimgs_0_1.max()}')\n",
    "    X_ori_LAB = rgb2lab_diff(ori_imgs_0_1,device)\n",
    "    advimgs_LAB = rgb2lab_diff(advimgs_0_1,device)\n",
    "    # print(f'advimgs: {advimgs}')\n",
    "    # print(f'ori_imgs: {ori_imgs}')\n",
    "    color_distance_map=ciede2000_diff(X_ori_LAB,advimgs_LAB,device)\n",
    "    # print(color_distance_map)\n",
    "    scores = torch.norm(color_distance_map.view(ori_imgs.shape[0],-1),dim=1)\n",
    "    # print(f'scores: {scores}')\n",
    "    # mean_scores = torch.mean(scores)\n",
    "    # 100\n",
    "    return torch.mean(scores)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrderedSet:\n",
    "    def __init__(self):\n",
    "        self._data = dict()\n",
    "\n",
    "    def add(self, item):\n",
    "        self._data[item] = None\n",
    "\n",
    "    def __contains__(self, item):\n",
    "        return item in self._data\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self._data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"OrderedSet({list(self._data)})\"\n",
    "\n",
    "    def discard(self, item):\n",
    "        self._data.pop(item, None)\n",
    "\n",
    "    def clear(self):\n",
    "        self._data.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_data_path = \"/data/home/yekai/github/MetaCloak/dataset/VGGFace2-clean\"\n",
    "clean_ref_dir_list = [os.path.join(ori_data_path,str(i),'set_C') for i in range(instance_num)]\n",
    "ori_pics_dir_list = [os.path.join(ori_data_path,str(i),'set_B') for i in range(instance_num)]\n",
    "# noisy_pics_dir = save_path\n",
    "\n",
    "\n",
    "noisy_pics_dir_list = [os.path.join(\"/data/home/yekai/github/MetaCloak/dataset/VGGFace2-MetaCloak480\",str(i),'set_B') for i in range(instance_num)]\n",
    "gen_pics_dir_list = [os.path.join(save_path,str(i)) for i in range(instance_num)]\n",
    "# clean_ref_dir = ori_pics_dir\n",
    "results = []\n",
    "key_set = OrderedSet()\n",
    "for i in tqdm(range(instance_num)):\n",
    "    score_dict = get_score(gen_pics_dir_list[i],clean_ref_dir_list[i])\n",
    "    # print(score_dict)\n",
    "    k_list = list(score_dict.keys())\n",
    "    tmp_score = []\n",
    "    for k in k_list:\n",
    "        key_set.add(k)\n",
    "        means = []\n",
    "        means.append(score_dict[k])\n",
    "        # print(f\"{k}_mean {np.mean(means)}\")\n",
    "        tmp_score.append(np.mean(means))\n",
    "        stds = []\n",
    "        stds.append(score_dict[k])\n",
    "        # print(f\"{k}_std {np.std(stds)}\")\n",
    "\n",
    "\n",
    "\n",
    "    original_data = load_data_by_picname(ori_pics_dir_list[i])\n",
    "    perturbed_data = load_data_by_picname(noisy_pics_dir_list[i])\n",
    "\n",
    "    # print(original_data-perturbed_data)\n",
    "    # print(perturbed_data)\n",
    "\n",
    "    # print(original_data[0][0])\n",
    "    # print(perturbed_data[0][0])\n",
    "\n",
    "    max_noise_r = find_max_pixel_change(perturbed_data, original_data)\n",
    "    noise_L0 = get_L0(perturbed_data, original_data)\n",
    "    noise_L1 = get_L1(perturbed_data, original_data)\n",
    "    noise_p = get_change_p(perturbed_data, original_data)\n",
    "    ciede2000_score = get_ciede2000_diff(original_data, perturbed_data)\n",
    "    \n",
    "    score_dict['max_noise_r'] = max_noise_r\n",
    "    score_dict['noise_L0'] = noise_L0\n",
    "    score_dict['pix_change_mean'] = noise_L1/(512*512)/2\n",
    "    score_dict['change_area_mean'] = noise_p*100\n",
    "    score_dict['ciede2000_score'] = ciede2000_score\n",
    "    tmp_score.append(max_noise_r)\n",
    "    tmp_score.append(noise_L0)\n",
    "    tmp_score.append(noise_L1)\n",
    "    tmp_score.append(noise_p*100)\n",
    "    tmp_score.append(float(ciede2000_score))\n",
    "    key_set.add('max_noise_r')\n",
    "    key_set.add('noise_L0')\n",
    "    key_set.add('pix_change_mean')\n",
    "    key_set.add('change_area_mean')\n",
    "    key_set.add('ciede2000_score')\n",
    "    results.append(tmp_score)\n",
    "    # break\n",
    "\n",
    "    # print(f\"max_noise_r {max_noise_r:.2f}\")\n",
    "    # print(f\"noise_L0 {noise_L0:.2f}\")\n",
    "    # print(f\"pix_change_mean {noise_L1:.2f}\")\n",
    "    # print(f\"change_area_mean {noise_p*100:.2f}\")\n",
    "    # print(f\"ciede2000_score {ciede2000_score:.2f}\")\n",
    "\n",
    "    # print(score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设 key_set 是列名，results 是二维列表（每行是一个 tmp_score）\n",
    "df = pd.DataFrame(results, columns=list(key_set))\n",
    "\n",
    "# 打印保留三位小数\n",
    "print(df.round(3).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"/data/home/yekai/github/sampleall/multi-dreambooth/gen_output/{taskname}.csv\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Metacloakp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
