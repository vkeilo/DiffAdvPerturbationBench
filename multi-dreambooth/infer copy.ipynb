{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/yekai/conda_envs/Metacloakp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-06-30 21:38:21.662971: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-30 21:38:21.723502: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-30 21:38:22.563694: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAPB_path: /data/home/yekai/github/DiffAdvPerturbationBench\n",
      "now_dir_path: /data/home/yekai/github/DiffAdvPerturbationBench/multi-dreambooth\n",
      "model_path: /data/home/yekai/github/DiffAdvPerturbationBench/multi-dreambooth/train_outputs/MultiATK_SD21_VGGFace2_r8_idx10_1idmatk_VV/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/yekai/conda_envs/Metacloakp/lib/python3.10/site-packages/diffusers/models/modeling_utils.py:101: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n",
      "/data/home/yekai/conda_envs/Metacloakp/lib/python3.10/site-packages/transformers/modeling_utils.py:415: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x75cb440fa8b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import torch\n",
    "from torch import autocast\n",
    "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "now_dir_path = os.getcwd()\n",
    "DAPB_path = os.path.dirname(now_dir_path)\n",
    "print(f\"DAPB_path: {DAPB_path}\")\n",
    "print(f\"now_dir_path: {now_dir_path}\")\n",
    "trained_model_path = os.path.join(now_dir_path, \"train_outputs\")\n",
    "gen_outputs_path = os.path.join(now_dir_path, \"gen_outputs\")\n",
    "\n",
    "# If you want to use previously trained model saved in gdrive, replace this with the full path of model in gdrive\n",
    "taskname = \"MultiATK_SD21_VGGFace2_r8_idx10_1idmatk_VV\"\n",
    "spwords_file = \"spwords.json\"\n",
    "totalsteps = 10000\n",
    "save_path = os.path.join(gen_outputs_path, taskname)\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "model_path = os.path.join(trained_model_path, taskname, str(totalsteps))\n",
    "print(f\"model_path: {model_path}\")\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_path, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
    "pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "pipe.enable_xformers_memory_efficient_attention()\n",
    "g_cuda = None\n",
    "#@markdown Can set random seed here for reproducibility.\n",
    "g_cuda = torch.Generator(device='cuda')\n",
    "seed = 52362 #@param {type:\"number\"}\n",
    "g_cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:31<00:00,  3.18it/s]\n",
      "100%|██████████| 100/100 [00:31<00:00,  3.19it/s]\n",
      "100%|██████████| 100/100 [00:31<00:00,  3.19it/s]\n",
      "100%|██████████| 100/100 [00:31<00:00,  3.19it/s]\n",
      "100%|██████████| 100/100 [00:31<00:00,  3.19it/s]\n",
      "100%|██████████| 100/100 [00:31<00:00,  3.19it/s]\n",
      "100%|██████████| 100/100 [00:31<00:00,  3.19it/s]\n",
      "100%|██████████| 100/100 [00:31<00:00,  3.18it/s]\n",
      "100%|██████████| 100/100 [00:31<00:00,  3.18it/s]\n",
      "100%|██████████| 100/100 [00:31<00:00,  3.18it/s]\n"
     ]
    }
   ],
   "source": [
    "special_text = []\n",
    "with open(f\"{now_dir_path}/{spwords_file}\", \"r\") as f:\n",
    "    special_text = json.load(f)[\"spwords_list\"]\n",
    "# special_text = [\n",
    "#     \"vux\", \"jiq\", \"qem\", \"zod\", \"dul\", \"wex\", \"hob\", \"taf\", \"yib\", \"nuz\",\n",
    "#     \"gax\", \"fep\", \"cim\", \"pyk\", \"teb\", \"lom\", \"sir\", \"dap\", \"kex\", \"yoc\",\n",
    "#     \"mib\", \"zow\", \"ruk\", \"hif\", \"cun\", \"baj\", \"tox\", \"geq\", \"vyx\", \"qum\",\n",
    "#     \"rek\", \"sov\", \"hax\", \"zud\", \"dif\", \"koy\", \"wen\", \"jib\", \"rax\", \"miv\",\n",
    "#     \"pob\", \"lut\", \"seg\", \"yox\", \"cud\", \"vig\", \"bez\", \"nam\", \"foj\", \"xur\"\n",
    "# ]\n",
    "# special_text = [\n",
    "#     \"vux\", \"jiq\", \"qem\", \"zod\", \"dul\"\n",
    "# ]\n",
    "# save_path = f\"/data/home/yekai/github/sampleall/multi-dreambooth/gen_output/{taskname}\"\n",
    "# if not os.path.exists(save_path):\n",
    "#     os.mkdir(save_path)\n",
    "instance_num = 10\n",
    "prompt_list = [f\"a photo of {special_text[i]} person\" for i in range(instance_num)] #@param {type:\"string\"}\n",
    "negative_prompt = \"\" #@param {type:\"string\"}\n",
    "num_samples = 16 #@param {type:\"number\"}\n",
    "guidance_scale = 7.5 #@param {type:\"number\"}\n",
    "num_inference_steps = 100 #@param {type:\"number\"}\n",
    "height = 512 #@param {type:\"number\"}\n",
    "width = 512 #@param {type:\"number\"}\n",
    "for i in range(instance_num):\n",
    "    with autocast(\"cuda\"), torch.inference_mode():\n",
    "        images = pipe(\n",
    "            prompt_list[i],\n",
    "            height=height,\n",
    "            width=width,\n",
    "            negative_prompt=negative_prompt,\n",
    "            num_images_per_prompt=num_samples,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            guidance_scale=guidance_scale,\n",
    "            generator=g_cuda\n",
    "        ).images\n",
    "    if not os.path.exists(f\"{save_path}/{i}\"):\n",
    "        os.mkdir(f\"{save_path}/{i}\")\n",
    "    for index, img in enumerate(images):\n",
    "        img.save(f\"{save_path}/{i}/{index}.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 评估生成图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "sys.path.append(\"/data/home/yekai/github/MetaCloak\")\n",
    "sys.path.append(\"/data/home/yekai/github/MetaCloak/robust_facecloak\")\n",
    "\n",
    "\n",
    "from eval_score import get_score\n",
    "import numpy as np\n",
    "from robust_facecloak.attacks.worker.differential_color_functions import rgb2lab_diff, ciede2000_diff\n",
    "from robust_facecloak.generic.data_utils import PromptDataset, load_data_by_picname\n",
    "\n",
    "def find_max_pixel_change(original_img, noisy_img):\n",
    "    diff = torch.abs(original_img - noisy_img)\n",
    "    \n",
    "    # Find the maximum pixel difference\n",
    "    max_change = torch.max(diff)\n",
    "    \n",
    "    return max_change.item()\n",
    "\n",
    "def get_L0(original_img, noisy_img):\n",
    "    diff = torch.abs(original_img - noisy_img)\n",
    "    diff_L0 = torch.sum(diff > 0, dim=(1, 2, 3))\n",
    "    # Find the maximum pixel difference\n",
    "    mean_L0 = torch.mean(diff_L0.float())\n",
    "    return mean_L0.item()\n",
    "\n",
    "def get_L1(original_img, noisy_img):\n",
    "    diff = torch.abs(original_img - noisy_img)\n",
    "    diff_L1 = torch.sum(diff, dim=(1, 2, 3))\n",
    "    mean_L1 = torch.mean(diff_L1.float())\n",
    "    return mean_L1.item()\n",
    "\n",
    "def get_change_p(original_img, noisy_img):\n",
    "    diff = torch.abs(original_img - noisy_img)\n",
    "    diff_L0_all = torch.sum(diff > 0, dim=(0, 1, 2, 3))\n",
    "    pix_num_all = original_img.shape[0] * original_img.shape[1] * original_img.shape[2] * original_img.shape[3]\n",
    "    change_p = diff_L0_all / pix_num_all\n",
    "    return change_p.item()\n",
    "\n",
    "def get_ciede2000_diff(ori_imgs,advimgs):\n",
    "    device = torch.device('cuda')\n",
    "    ori_imgs_0_1 = ori_imgs/255\n",
    "    advimgs_0_1 = advimgs/255\n",
    "    advimgs_0_1.clamp_(0,1)\n",
    "    # print(f'ori_imgs_0_1.min:{ori_imgs_0_1.min()}, ori_imgs_0_1.max:{ori_imgs_0_1.max()}')\n",
    "    # print(f'advimgs_0_1.min:{advimgs_0_1.min()}, advimgs_0_1.max:{advimgs_0_1.max()}')\n",
    "    X_ori_LAB = rgb2lab_diff(ori_imgs_0_1,device)\n",
    "    advimgs_LAB = rgb2lab_diff(advimgs_0_1,device)\n",
    "    # print(f'advimgs: {advimgs}')\n",
    "    # print(f'ori_imgs: {ori_imgs}')\n",
    "    color_distance_map=ciede2000_diff(X_ori_LAB,advimgs_LAB,device)\n",
    "    # print(color_distance_map)\n",
    "    scores = torch.norm(color_distance_map.view(ori_imgs.shape[0],-1),dim=1)\n",
    "    # print(f'scores: {scores}')\n",
    "    # mean_scores = torch.mean(scores)\n",
    "    # 100\n",
    "    return torch.mean(scores)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrderedSet:\n",
    "    def __init__(self):\n",
    "        self._data = dict()\n",
    "\n",
    "    def add(self, item):\n",
    "        self._data[item] = None\n",
    "\n",
    "    def __contains__(self, item):\n",
    "        return item in self._data\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self._data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"OrderedSet({list(self._data)})\"\n",
    "\n",
    "    def discard(self, item):\n",
    "        self._data.pop(item, None)\n",
    "\n",
    "    def clear(self):\n",
    "        self._data.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]2025-04-15 18:33:50.235442: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2025-04-15 18:33:50.236394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 289 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:41:00.0, compute capability: 8.9\n",
      "2025-04-15 18:33:53.471626: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:447] Loaded runtime CuDNN library: 8.3.2 but source was compiled with: 8.9.4.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2025-04-15 18:33:53.472249: W external/local_xla/xla/stream_executor/stream.h:1447] attempting to perform DNN operation using StreamExecutor without DNN support\n",
      "  0%|          | 0/5 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node model/bn_data/FusedBatchNormV3 defined at (most recent call last):\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 701, in start\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n\n  File \"/tmp/ipykernel_982808/1421441054.py\", line 13, in <module>\n\n  File \"/data/home/yekai/github/MetaCloak/robust_facecloak/eval_score.py\", line 222, in get_score\n\n  File \"/data/home/yekai/github/MetaCloak/robust_facecloak/eval_score.py\", line 68, in __call__\n\n  File \"/data/home/yekai/github/MetaCloak/robust_facecloak/eval_score.py\", line 57, in __loop_to_get_overall_score__\n\n  File \"/data/home/yekai/github/MetaCloak/robust_facecloak/eval_score.py\", line 203, in FDSR_get_score\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/deepface/DeepFace.py\", line 842, in extract_faces\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/deepface/commons/functions.py\", line 167, in extract_faces\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/deepface/detectors/FaceDetector.py\", line 81, in detect_faces\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/deepface/detectors/RetinaFaceWrapper.py\", line 19, in detect_face\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/retinaface/RetinaFace.py\", line 123, in detect_faces\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/engine/training.py\", line 555, in error_handler\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/engine/training.py\", line 560, in error_handler\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/layers/normalization/batch_normalization.py\", line 597, in call\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/layers/normalization/batch_normalization.py\", line 990, in _fused_batch_norm\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/utils/control_flow_util.py\", line 108, in smart_cond\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/layers/normalization/batch_normalization.py\", line 979, in _fused_batch_norm_inference\n\ncuDNN launch failure : input shape ([1,1024,1024,3])\n\t [[{{node model/bn_data/FusedBatchNormV3}}]] [Op:__inference_function_8077]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m key_set \u001b[38;5;241m=\u001b[39m OrderedSet()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(instance_num)):\n\u001b[0;32m---> 13\u001b[0m     score_dict \u001b[38;5;241m=\u001b[39m \u001b[43mget_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen_pics_dir_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclean_ref_dir_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# print(score_dict)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     k_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(score_dict\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32m~/github/MetaCloak/robust_facecloak/eval_score.py:222\u001b[0m, in \u001b[0;36mget_score\u001b[0;34m(image_dir, clean_ref_dir, type_name)\u001b[0m\n\u001b[1;32m    220\u001b[0m result_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m type_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mface\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 222\u001b[0m     result_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSDS\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mFDSR_Scorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen_image_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_ref_db\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean_ref_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m     result_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCLIP_Face_IQA\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m CLIP_Face_Scorer(gen_image_dir\u001b[38;5;241m=\u001b[39mimage_dir, clean_ref_db\u001b[38;5;241m=\u001b[39mclean_ref_dir, type_name\u001b[38;5;241m=\u001b[39mtype_name)\n\u001b[1;32m    224\u001b[0m     result_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLIQE_Scene_Human\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m  LIQE_Scene_Human_Scorer(gen_image_dir\u001b[38;5;241m=\u001b[39mimage_dir, clean_ref_db\u001b[38;5;241m=\u001b[39mclean_ref_dir, type_name\u001b[38;5;241m=\u001b[39mtype_name)\n",
      "File \u001b[0;32m~/github/MetaCloak/robust_facecloak/eval_score.py:68\u001b[0m, in \u001b[0;36mScoreEval.__call__\u001b[0;34m(self, gen_image_dir, clean_ref_db, type_name)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, gen_image_dir, clean_ref_db\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, type_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mface\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__loop_to_get_overall_score__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mgen_image_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_ref_db\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/github/MetaCloak/robust_facecloak/eval_score.py:57\u001b[0m, in \u001b[0;36mScoreEval.__loop_to_get_overall_score__\u001b[0;34m(self, gen_image_dir, clean_ref_db, type_name)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(files_db_gen)):\n\u001b[1;32m     56\u001b[0m     gen_i \u001b[38;5;241m=\u001b[39m files_db_gen[i]\n\u001b[0;32m---> 57\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_get_score_of_one_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_ref_db\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend(score)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# filter out nan and np.inf \u001b[39;00m\n",
      "File \u001b[0;32m~/github/MetaCloak/robust_facecloak/eval_score.py:203\u001b[0m, in \u001b[0;36mFDSR_get_score\u001b[0;34m(gen_i, clean_ref_db, model, type_name)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mFDSR_get_score\u001b[39m(gen_i, clean_ref_db\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretinaface\u001b[39m\u001b[38;5;124m'\u001b[39m, type_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mface\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 203\u001b[0m     face_obj \u001b[38;5;241m=\u001b[39m \u001b[43mDeepFace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_faces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgen_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(face_obj)):\n",
      "File \u001b[0;32m~/miniconda3/envs/Metacloak/lib/python3.9/site-packages/deepface/DeepFace.py:842\u001b[0m, in \u001b[0;36mextract_faces\u001b[0;34m(img_path, target_size, detector_backend, enforce_detection, align, grayscale)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;124;03mThis function applies pre-processing stages of a face recognition pipeline\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;124;03mincluding detection and alignment\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    837\u001b[0m \n\u001b[1;32m    838\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    840\u001b[0m resp_objs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 842\u001b[0m img_objs \u001b[38;5;241m=\u001b[39m \u001b[43mfunctions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_faces\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrayscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrayscale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m    \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_detection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img, region, confidence \u001b[38;5;129;01min\u001b[39;00m img_objs:\n\u001b[1;32m    852\u001b[0m     resp_obj \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/miniconda3/envs/Metacloak/lib/python3.9/site-packages/deepface/commons/functions.py:167\u001b[0m, in \u001b[0;36mextract_faces\u001b[0;34m(img, target_size, detector_backend, grayscale, enforce_detection, align)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     face_detector \u001b[38;5;241m=\u001b[39m FaceDetector\u001b[38;5;241m.\u001b[39mbuild_model(detector_backend)\n\u001b[0;32m--> 167\u001b[0m     face_objs \u001b[38;5;241m=\u001b[39m \u001b[43mFaceDetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_faces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_detector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# in case of no face found\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(face_objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m enforce_detection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/Metacloak/lib/python3.9/site-packages/deepface/detectors/FaceDetector.py:81\u001b[0m, in \u001b[0;36mdetect_faces\u001b[0;34m(face_detector, detector_backend, img, align)\u001b[0m\n\u001b[1;32m     78\u001b[0m detect_face_fn \u001b[38;5;241m=\u001b[39m backends\u001b[38;5;241m.\u001b[39mget(detector_backend)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m detect_face_fn:  \u001b[38;5;66;03m# pylint: disable=no-else-return\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_face_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface_detector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# obj stores list of (detected_face, region, confidence)\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m~/miniconda3/envs/Metacloak/lib/python3.9/site-packages/deepface/detectors/RetinaFaceWrapper.py:19\u001b[0m, in \u001b[0;36mdetect_face\u001b[0;34m(face_detector, img, align)\u001b[0m\n\u001b[1;32m     15\u001b[0m resp \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# --------------------------\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[43mRetinaFace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_faces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mface_detector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m face_idx \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mkeys():\n",
      "File \u001b[0;32m~/miniconda3/envs/Metacloak/lib/python3.9/site-packages/retinaface/RetinaFace.py:123\u001b[0m, in \u001b[0;36mdetect_faces\u001b[0;34m(img_path, threshold, model, allow_upscaling)\u001b[0m\n\u001b[1;32m    121\u001b[0m landmarks_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    122\u001b[0m im_tensor, im_info, im_scale \u001b[38;5;241m=\u001b[39m preprocess\u001b[38;5;241m.\u001b[39mpreprocess_image(img, allow_upscaling)\n\u001b[0;32m--> 123\u001b[0m net_out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m net_out \u001b[38;5;241m=\u001b[39m [elt\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m elt \u001b[38;5;129;01min\u001b[39;00m net_out]\n\u001b[1;32m    125\u001b[0m sym_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/Metacloak/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/Metacloak/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node model/bn_data/FusedBatchNormV3 defined at (most recent call last):\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 701, in start\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n\n  File \"/tmp/ipykernel_982808/1421441054.py\", line 13, in <module>\n\n  File \"/data/home/yekai/github/MetaCloak/robust_facecloak/eval_score.py\", line 222, in get_score\n\n  File \"/data/home/yekai/github/MetaCloak/robust_facecloak/eval_score.py\", line 68, in __call__\n\n  File \"/data/home/yekai/github/MetaCloak/robust_facecloak/eval_score.py\", line 57, in __loop_to_get_overall_score__\n\n  File \"/data/home/yekai/github/MetaCloak/robust_facecloak/eval_score.py\", line 203, in FDSR_get_score\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/deepface/DeepFace.py\", line 842, in extract_faces\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/deepface/commons/functions.py\", line 167, in extract_faces\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/deepface/detectors/FaceDetector.py\", line 81, in detect_faces\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/deepface/detectors/RetinaFaceWrapper.py\", line 19, in detect_face\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/retinaface/RetinaFace.py\", line 123, in detect_faces\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/engine/training.py\", line 555, in error_handler\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/engine/training.py\", line 560, in error_handler\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/engine/training.py\", line 590, in __call__\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/engine/functional.py\", line 515, in call\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/engine/functional.py\", line 672, in _run_internal_graph\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/engine/base_layer.py\", line 1149, in __call__\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 96, in error_handler\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/layers/normalization/batch_normalization.py\", line 597, in call\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/layers/normalization/batch_normalization.py\", line 990, in _fused_batch_norm\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/utils/control_flow_util.py\", line 108, in smart_cond\n\n  File \"/data/home/yekai/miniconda3/envs/Metacloak/lib/python3.9/site-packages/keras/src/layers/normalization/batch_normalization.py\", line 979, in _fused_batch_norm_inference\n\ncuDNN launch failure : input shape ([1,1024,1024,3])\n\t [[{{node model/bn_data/FusedBatchNormV3}}]] [Op:__inference_function_8077]"
     ]
    }
   ],
   "source": [
    "ori_data_path = \"/data/home/yekai/github/MetaCloak/dataset/VGGFace2-clean\"\n",
    "clean_ref_dir_list = [os.path.join(ori_data_path,str(i),'set_C') for i in range(instance_num)]\n",
    "ori_pics_dir_list = [os.path.join(ori_data_path,str(i),'set_B') for i in range(instance_num)]\n",
    "# noisy_pics_dir = save_path\n",
    "\n",
    "\n",
    "noisy_pics_dir_list = [os.path.join(\"/data/home/yekai/github/MetaCloak/dataset/VGGFace2-MetaCloak480\",str(i),'set_B') for i in range(instance_num)]\n",
    "gen_pics_dir_list = [os.path.join(save_path,str(i)) for i in range(instance_num)]\n",
    "# clean_ref_dir = ori_pics_dir\n",
    "results = []\n",
    "key_set = OrderedSet()\n",
    "for i in tqdm(range(instance_num)):\n",
    "    score_dict = get_score(gen_pics_dir_list[i],clean_ref_dir_list[i])\n",
    "    # print(score_dict)\n",
    "    k_list = list(score_dict.keys())\n",
    "    tmp_score = []\n",
    "    for k in k_list:\n",
    "        key_set.add(k)\n",
    "        means = []\n",
    "        means.append(score_dict[k])\n",
    "        # print(f\"{k}_mean {np.mean(means)}\")\n",
    "        tmp_score.append(np.mean(means))\n",
    "        stds = []\n",
    "        stds.append(score_dict[k])\n",
    "        # print(f\"{k}_std {np.std(stds)}\")\n",
    "\n",
    "\n",
    "\n",
    "    original_data = load_data_by_picname(ori_pics_dir_list[i])\n",
    "    perturbed_data = load_data_by_picname(noisy_pics_dir_list[i])\n",
    "\n",
    "    # print(original_data-perturbed_data)\n",
    "    # print(perturbed_data)\n",
    "\n",
    "    # print(original_data[0][0])\n",
    "    # print(perturbed_data[0][0])\n",
    "\n",
    "    max_noise_r = find_max_pixel_change(perturbed_data, original_data)\n",
    "    noise_L0 = get_L0(perturbed_data, original_data)\n",
    "    noise_L1 = get_L1(perturbed_data, original_data)\n",
    "    noise_p = get_change_p(perturbed_data, original_data)\n",
    "    ciede2000_score = get_ciede2000_diff(original_data, perturbed_data)\n",
    "    \n",
    "    score_dict['max_noise_r'] = max_noise_r\n",
    "    score_dict['noise_L0'] = noise_L0\n",
    "    score_dict['pix_change_mean'] = noise_L1/(512*512)/2\n",
    "    score_dict['change_area_mean'] = noise_p*100\n",
    "    score_dict['ciede2000_score'] = ciede2000_score\n",
    "    tmp_score.append(max_noise_r)\n",
    "    tmp_score.append(noise_L0)\n",
    "    tmp_score.append(noise_L1)\n",
    "    tmp_score.append(noise_p*100)\n",
    "    tmp_score.append(float(ciede2000_score))\n",
    "    key_set.add('max_noise_r')\n",
    "    key_set.add('noise_L0')\n",
    "    key_set.add('pix_change_mean')\n",
    "    key_set.add('change_area_mean')\n",
    "    key_set.add('ciede2000_score')\n",
    "    results.append(tmp_score)\n",
    "    # break\n",
    "\n",
    "    # print(f\"max_noise_r {max_noise_r:.2f}\")\n",
    "    # print(f\"noise_L0 {noise_L0:.2f}\")\n",
    "    # print(f\"pix_change_mean {noise_L1:.2f}\")\n",
    "    # print(f\"change_area_mean {noise_p*100:.2f}\")\n",
    "    # print(f\"ciede2000_score {ciede2000_score:.2f}\")\n",
    "\n",
    "    # print(score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设 key_set 是列名，results 是二维列表（每行是一个 tmp_score）\n",
    "df = pd.DataFrame(results, columns=list(key_set))\n",
    "\n",
    "# 打印保留三位小数\n",
    "print(df.round(3).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"/data/home/yekai/github/sampleall/multi-dreambooth/gen_output/{taskname}.csv\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Metacloakp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
